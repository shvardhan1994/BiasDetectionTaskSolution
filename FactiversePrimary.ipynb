{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FactiversePrimary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTUGEKSsi-Tm"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfyu3GHjkTlu"
      },
      "source": [
        "# Preprocessing of Data\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "nlp = spacy.load(\"en_core_web_sm\",disable=[\"tagger\", \"parser\"])\n",
        "def preprocess(text):\n",
        "    # TODO: Replace the next line with your own code.\n",
        "    doc = nlp(text)\n",
        "    token_list = []\n",
        "    for token in doc:\n",
        "        if token.is_stop == False and token.lemma_.isalpha() and len(token) > 3:\n",
        "            token_list.append(token.lemma_)\n",
        "    return(token_list)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k16cdeK142Tp"
      },
      "source": [
        "def datareadiness(data,preproflag):\n",
        "  # Removing null rows\n",
        "  ind = np.where(data['body'].isnull() == True)[0].tolist()\n",
        "  data = data.drop(ind)\n",
        "  data = data.reset_index()\n",
        "\n",
        "  # Preprocessing the text\n",
        "  if preproflag=='Y':\n",
        "    for i in range(len(data)):\n",
        "      data['body'][i] = \" \".join(preprocess(data['body'][i]))\n",
        "\n",
        "    return data\n",
        "  else:\n",
        "    return data\n",
        "  \n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2zDSjNYgvGw"
      },
      "source": [
        "from typing import Tuple, List\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "class BiasClassifier:\n",
        "    def __init__(self,model,vectorizer):\n",
        "        self.model = model\n",
        "        self.vectorizer = vectorizer\n",
        "        \n",
        "    \n",
        "    def fit(self, train_file_path):\n",
        "        \"\"\"Train a classifier model after reading and extracting features from \n",
        "        train_file_path.\n",
        "\n",
        "        Args:\n",
        "            train_file_path: String path to the training data as a json, you \n",
        "            may assume instances have labels.\n",
        "\n",
        "        Returns:\n",
        "            A tuple of list of document id and prediction label and \n",
        "        \"\"\"\n",
        "        # TODO write code to extract features from train_file_path and \n",
        "        # train the model\n",
        "        self.train_file_path = train_file_path\n",
        "        train_data = pd.read_json(self.train_file_path)\n",
        "        newtrain_data = datareadiness(train_data,'N')\n",
        "\n",
        "        trainX = newtrain_data.body.values\n",
        "        trainY = pd.factorize(newtrain_data.bias.values)[0]\n",
        "\n",
        "        # Tranforming the text into vectorized form using CountVectorizer() and creating a pipeline of Vectorzer and CLassification method\n",
        "\n",
        "        pipe = Pipeline([('countvectorizer', self.vectorizer),('XGB',self.model)])\n",
        "        self.model_fit = pipe.fit(trainX,trainY)\n",
        "\n",
        "        return self.model_fit\n",
        "    \n",
        "    def eval(self, val_file_path, model_fit):\n",
        "    # -> Tuple[List[Dict[str, float]], classification_report]:\n",
        "        \"\"\"Evaluates the test data given in test_file_path after reading and\n",
        "         extracting features.\n",
        "\n",
        "        Args:\n",
        "            test_file_path: String path to the test data, you may assume \n",
        "            instances have labels.\n",
        "\n",
        "        Returns:\n",
        "            A tuple of list of document id and prediction label and \n",
        "            evaluation summary in the form of sklearn classification_report.\n",
        "        \"\"\"\n",
        "        # TODO write code to extract features from test_file_path and \n",
        "        # test the model\n",
        "        self.val_file_path = val_file_path\n",
        "        self.model_fit = model_fit\n",
        "        val_data = pd.read_json(self.val_file_path)\n",
        "        newval_data = datareadiness(val_data,'N')\n",
        "\n",
        "        valX = newval_data.body.values\n",
        "        valY = pd.factorize(newval_data.bias.values)[0]\n",
        "\n",
        "        # Predicting the bias for validation dataset\n",
        "\n",
        "        self.predeval = self.model_fit.predict(valX)\n",
        "        self.predorglabel = ['Right' if v == 0 else 'Left' if v == 2 else 'Center' for v in self.predeval]\n",
        "        self.dicteval = {}\n",
        "        for i in range(len(self.predorglabel)):\n",
        "          self.dicteval[newval_data['id'][i]] = self.predorglabel[i]\n",
        "        \n",
        "        self.summaryeval = classification_report(valY,self.predeval, target_names=['Right','Left','Center'])\n",
        "        self.oplist = [self.dicteval,self.summaryeval]\n",
        "        self.optuple = (self.oplist)\n",
        "        return self.optuple\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, test_file_path,model_fit): \n",
        "    # -> List[Dict[str, float]]:\n",
        "        \"\"\"Evaluates the test data given in test_file_path after reading and\n",
        "         extracting features.\n",
        "\n",
        "        Args:\n",
        "            test_file_path: String path to the test data, the instances do not \n",
        "            have labels.\n",
        "\n",
        "        Returns:\n",
        "            A list of document id and prediction label.\n",
        "        \"\"\"\n",
        "        # TODO write code to extract features from test_file_path and \n",
        "        # predict the labels for the model.\n",
        "        self.test_file_path = test_file_path\n",
        "        self.model_fit = model_fit\n",
        "        test_data = pd.read_json(self.test_file_path)\n",
        "        newtest_data = datareadiness(test_data,'N')\n",
        "\n",
        "        testX = newtest_data.body.values\n",
        "        # testY = pd.factorize(newtest_data.bias.values)[0]\n",
        "\n",
        "        # Predicting the bias for validation dataset\n",
        "\n",
        "        self.predtest = self.model_fit.predict(testX)\n",
        "        self.predtestorglabel = ['Right' if v == 0 else 'Left' if v == 2 else 'Center' for v in self.predeval]\n",
        "        self.dicttest = {}\n",
        "        for i in range(len(self.predtestorglabel)):\n",
        "          self.dicttest[newtest_data['id'][i]] = self.predtestorglabel[i]\n",
        "        \n",
        "        # self.summaryeval = classification_report(testY,self.predeval, target_names=['Right','Left','Center'])\n",
        "\n",
        "        return [self.dicttest]\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB1ShPRigvIY"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model = XGBClassifier()\n",
        "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
        "\n",
        "clf = BiasClassifier(model,vectorizer)\n",
        "model_fit = clf.fit(train_file_path = '/content/bias_articles_train.json')\n",
        "opeval = clf.eval(val_file_path='/content/bias_articles_dev.json',model_fit = model_fit)\n",
        "optest = clf.predict(test_file_path='/content/bias_articles_test.json',model_fit = model_fit)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdrjesVugOan",
        "outputId": "08b3fad0-3640-474d-d2f6-edbfe1083b61"
      },
      "source": [
        "print('Classification report of Validation dataset\\n\\n',opeval[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report of Validation dataset\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Right       0.71      0.33      0.45        15\n",
            "        Left       0.33      0.29      0.31         7\n",
            "      Center       0.35      0.75      0.48         8\n",
            "\n",
            "    accuracy                           0.43        30\n",
            "   macro avg       0.47      0.46      0.41        30\n",
            "weighted avg       0.53      0.43      0.43        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfFYZVqJf99s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "966592a4-a0c2-42d3-8475-90bc12073e26"
      },
      "source": [
        "print('Dictionary of document id of validation dataset and predicted labels \\n',opeval[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary of documente id of validation dataset and predicted labels \n",
            " {240: 'Right', 241: 'Left', 242: 'Left', 243: 'Left', 244: 'Center', 245: 'Center', 246: 'Left', 247: 'Left', 248: 'Left', 249: 'Right', 250: 'Left', 251: 'Right', 252: 'Center', 253: 'Left', 254: 'Left', 255: 'Left', 256: 'Left', 257: 'Center', 258: 'Center', 259: 'Left', 260: 'Center', 261: 'Left', 262: 'Right', 263: 'Right', 264: 'Left', 265: 'Left', 266: 'Left', 267: 'Left', 268: 'Right', 269: 'Right'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8kMmhzPifSi",
        "outputId": "2daf2685-a019-42e7-eb48-4155186097ba"
      },
      "source": [
        "print('Dictionary of document id of test dataset and predicted labels \\n',optest)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary of document id of test dataset and predicted labels \n",
            " [{270: 'Right', 271: 'Left', 272: 'Left', 273: 'Left', 274: 'Center', 275: 'Center', 276: 'Left', 277: 'Left', 278: 'Left', 279: 'Right', 280: 'Left', 281: 'Right', 282: 'Center', 283: 'Left', 284: 'Left', 285: 'Left', 286: 'Left', 287: 'Center', 288: 'Center', 289: 'Left', 290: 'Center', 291: 'Left', 292: 'Right', 293: 'Right', 294: 'Left', 295: 'Left', 296: 'Left', 297: 'Left', 298: 'Right', 299: 'Right'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL2jcJxProCw"
      },
      "source": [
        "The text classification task was handled in two directions.\n",
        "This notebook (FactiversePrimary.ipynb) contains the final implementation of the best performing classifier method after hyper parameter tuning. Classifier training and prediction has been implemented in the BiasClassifier class as per the skeleton code given. Some slight modifications has been done to the skeleton code based on my understanding of OOP in python. The results of the final model are printed as in this notebook for your reference.\n",
        "\n",
        "The second notebook (FactiverseSecondary.ipynb) contains the following,\n",
        "* Initial data visulalization to check if the dataset is balanced amongst 3 classes. We can see from the histogram that count of speeches with 'Center' as the label is almost double compared to equally distributed count of speeches with label 'Right' and 'Left'. \n",
        "Since the total count of training dataset itself is very small (239), the need for balancing dataset with same count of speeches with their respective lables is not suggested (However, later in the training phase with multiple classifiers, after using the balanced dataset, the accuracy did not improve).\n",
        "\n",
        "* The need for preprocessing the data in terms of sentence lemmatization, removing stop words, removing null records was carried out. The classifiers were trained first on original texts and later on preprocessed texts to find out which resulted in better accuracy.\n",
        "\n",
        "* The initial approach in solving text classification problem was to try the baseline ML classification techniques. However, since the data is in the text format, the same had to be transformed or vectorized to train a classifier. Couuntvectorizer() method of transformation was choosed since it widely used in the of NLP and and one of the effective baseline method which uses word level tokenization. The numerical vector for each word is based on count of each word present in the sentence. The default hyper parameters were used except for ngram_range(since the results were better). Once the words in the speeches were transformed, the response labels were factorized to 0,1,2 from 'Right,Left,Center). A pipeline was built consisting of countvectorizer for transforming the data and the classifier.\n",
        "Baseline methods like Logistic regression, Support vector classifier, Decision tree and XGBoost Classifer were built. XGB classifier outperformed rest of the classifiers resulting in slightly better accuracy but not the best I expected. The major reason which I believe is the length of the dataset. The dataset was very small and to expect a good result using baseline methods, the same has to be large enough at the least in thousands. \n",
        "Few of the hyper parmeters were tweaked in all classifiers but XGBClassifier with default parametes perfomed better than rest. \n",
        "\n",
        "* The second approach in solving this classification problem was to train the dataset on pre trained model BERT and fine tune it our task. BERT has a history of dealing well with smaller datasets since the pre trained model is already trained in billion of word corpus and incredibly famous because of self attention mechansim which captures the context of the sentence in both directions. Our dataset was fine tuned and transformed into tokens as expected by BERT. However, the end results were very bad even after tuning parameters like batch size, epochs, learning rate. The reason I believe is the same as mentioned earlier, is that the model cannot well trained enough with such less data. Another reason is the length of each sentence in the training dataset. Certain BERT model has a limitation in terms of sentence length (512) and since the average length of given sentences is around 3900 words. So it is important to pick words that are important in making classification and for task like text classification, one can argue that it would be computationaly expensive. Hence, BERT was not a good choice in this case and specific task. \n",
        "\n",
        "* The third approach was to try other deep learning models like regular word embedding, LSTM and GRU. Instead of vectorizing the words using countvectorizer(), an embedding vector is used to train the model. Embedding vector provides better sense of meaning to each word than count vectorizer(since it based on only count). Unfortunately, the results were not great and were close to results of XGB classifier but not better. The hyper parmeters in this case were not fine tuned because of the intution I had that it could not perform any better nor outperform XGB classifier and also computationaly quite expensive.\n",
        "\n",
        "* Ultimately, after trying different models ranging from baseline to state of the art, for this particular task, XGB Classifier performed better. Since I am more of a functional programmer and based on my experience and understanding of using classes, I was able to implement the choosen method to fit inside the given code skeleton and the same can be found in FactiversePrimary.ipynb notebook. \n",
        "\n",
        "Note : \n",
        "* The code for implementing BERT,LSTM and GRU was borrowed from my own work which I had used for different text classification problem. The same can be verified in github account in NLPProjects repository. \n",
        "I have used Google colab for coding in both the notebooks, hence there could be spacing issues if opened in other environments also the path of the input files can change.\n",
        "\n",
        "* I have promptly tried the best possible ways this problem can be solved and if I had missed out on something, I would be much interested in learning and improving my skills. Also, I would be happy to answer any question regarding the task and my choices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmSruiMJroGW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfcMEntfroJk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5veompT6roNE"
      },
      "source": [
        ""
      ]
    }
  ]
}